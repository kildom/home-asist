{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dfa0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8572aaa",
   "metadata": {},
   "source": [
    "# Download model from hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "hub_model = hub.load('https://tfhub.dev/google/speech_embedding/1')\n",
    "tf.saved_model.save(hub_model, \"../models/conv_speech_embedding\", signatures={x: hub_model.signatures[x] for x in dict(hub_model.signatures).keys()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e57ad",
   "metadata": {},
   "source": [
    "## or load from already downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff82fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title: Load and Save TensorFlow Hub Model\n",
    "hub_model = tf.saved_model.load(\"../models/conv_speech_embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603ee26",
   "metadata": {},
   "source": [
    "## convert to tflite\n",
    "Można podlądać w https://netron.app/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_concrete_functions([hub_model.signatures[\"default\"]])\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # TFLite native ops\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS     # Include TF ops in TFLite\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "with open(\"../models/conv_speech_embedding.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25555d93",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model1():\n",
    "    model1 = tf.lite.Interpreter(model_path=str('../models/embedding_model.tflite'), experimental_preserve_all_tensors=True)\n",
    "    model1.resize_tensor_input(\n",
    "        model1.get_input_details()[0]['index'],\n",
    "        [1, 76, 32, 1],\n",
    "        strict=True)\n",
    "    model1.allocate_tensors()\n",
    "    model1_in = model1.get_input_details()[0]['index']\n",
    "    model1_out = model1.get_output_details()[0]['index']\n",
    "    return model1, model1_in, model1_out\n",
    "\n",
    "def get_model2(samples):\n",
    "    model2 = tf.lite.Interpreter(model_path=str('../models/conv_speech_embedding.tflite'), experimental_preserve_all_tensors=True)\n",
    "    model2.resize_tensor_input(\n",
    "        model2.get_input_details()[0]['index'],\n",
    "        [1, samples],\n",
    "        strict=True)\n",
    "    model2.allocate_tensors()\n",
    "    model2_in = model2.get_input_details()[0]['index']\n",
    "    model2_out = model2.get_output_details()[0]['index']\n",
    "    return model2, model2_in, model2_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d059f748",
   "metadata": {},
   "source": [
    "## Compare original model from HUB with converted tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d54b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(12480).astype(np.float32)\n",
    "res1 = hub_model.signatures['default'](default=data.reshape(1, -1))['default']\n",
    "model2, model2_in, model2_out = get_model2(data.shape[0])\n",
    "model2.set_tensor(model2_in, data.reshape(1, -1))\n",
    "model2.invoke()\n",
    "res2 = model2.get_tensor(model2_out)\n",
    "diff = np.abs(res2 - res1)\n",
    "print(\"Difference between outputs absolute:\", np.max(diff), np.mean(diff), np.min(diff))\n",
    "diff = np.abs(res2 - res1) / np.maximum(np.abs(res2), np.abs(res1))\n",
    "print(\"Difference between outputs relative:\", np.max(diff), np.mean(diff), np.min(diff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4ae771",
   "metadata": {},
   "source": [
    "## Get mel spec from random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5009c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(12480).astype(np.float32)\n",
    "model2, model2_in, model2_out = get_model2(data.shape[0])\n",
    "model2.set_tensor(model2_in, data.reshape(1, -1))\n",
    "model2.invoke()\n",
    "output2 = model2.get_tensor(model2_out)\n",
    "print(output2.shape)\n",
    "mel_output = model2.get_tensor(67)\n",
    "print(mel_output.shape)\n",
    "\n",
    "model1, model1_in, model1_out = get_model1()\n",
    "model1.set_tensor(model1_in, mel_output)\n",
    "model1.invoke()\n",
    "output1 = model1.get_tensor(model1_out)\n",
    "print(output1.shape)\n",
    "\n",
    "diff = np.abs(model1.get_tensor(43) - model2.get_tensor(68))\n",
    "print(\"Difference between outputs:\", np.max(diff), np.mean(diff), np.min(diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(12480).astype(np.float32)\n",
    "\n",
    "def check_layers(input_index, output_index, callbacks: list[any]):\n",
    "    model2, model2_in, model2_out = get_model2(data.shape[0])\n",
    "    model2.set_tensor(model2_in, data.reshape(1, -1))\n",
    "    model2.invoke()\n",
    "    x = model2.get_tensor(input_index)\n",
    "    for callback in callbacks:\n",
    "        x = callback(x)\n",
    "    exp = model2.get_tensor(output_index)\n",
    "    if input_index == output_index:\n",
    "        diff = np.abs(x)\n",
    "    else:\n",
    "        diff = np.abs(exp - x)\n",
    "    print(\"Difference between outputs:\", np.max(diff), np.mean(diff), np.min(diff))\n",
    "\n",
    "def layer_pad(x: 'npt.NDArray[np.float32]') -> 'npt.NDArray[np.float32]':\n",
    "    return np.pad(x, ((0, 0), (0, 0), (1, 1), (0, 0)), mode='constant', constant_values=0)\n",
    "\n",
    "def layer_conv1(x: 'npt.NDArray[np.float32]') -> 'npt.NDArray[np.float32]':\n",
    "    conv1_filter = np.load('../models/vars/conv1_filter.npy')\n",
    "    conv1_mul = np.load('../models/vars/conv1_mul.npy')\n",
    "    conv1_filter = conv1_filter * conv1_mul[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "    conv1_filter = np.transpose(conv1_filter, (1, 2, 3, 0))\n",
    "    x = tf.nn.conv2d(x, filters=conv1_filter, strides=[1, 1, 1, 1], padding='VALID', data_format='NHWC').numpy()\n",
    "    x = np.maximum(0, x)\n",
    "    conv1_add = np.load('../models/vars/conv1_add.npy')\n",
    "    return x + conv1_add\n",
    "\n",
    "def layer_relu(x: 'npt.NDArray[np.float32]') -> 'npt.NDArray[np.float32]':\n",
    "    x = np.maximum(0, x) + 0.2 * (x - np.maximum(0, x))\n",
    "    return np.maximum(-0.4, x)\n",
    "\n",
    "def layer_conv(filter_file: str, bias_file: str, padding: str):\n",
    "    filter = np.load('../models/vars/' + filter_file)\n",
    "    filter = np.transpose(filter, (1, 2, 3, 0))\n",
    "    bias = np.load('../models/vars/' + bias_file)\n",
    "    def exec(x: 'npt.NDArray[np.float32]') -> 'npt.NDArray[np.float32]':\n",
    "        x = tf.nn.conv2d(x, filters=filter, strides=[1, 1, 1, 1], padding=padding, data_format='NHWC').numpy()\n",
    "        x = x + bias\n",
    "        return x\n",
    "    return exec\n",
    "\n",
    "def max_pool2x2(x: 'npt.NDArray[np.float32]') -> 'npt.NDArray[np.float32]':\n",
    "    return tf.nn.max_pool2d(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID', data_format='NHWC').numpy()\n",
    "\n",
    "def max_pool1x2(x: 'npt.NDArray[np.float32]') -> 'npt.NDArray[np.float32]':\n",
    "    return tf.nn.max_pool2d(x, ksize=[1, 1, 2, 1], strides=[1, 1, 2, 1], padding='VALID', data_format='NHWC').numpy()\n",
    "\n",
    "\n",
    "check_layers(67, 67, [])\n",
    "check_layers(67, 68, [layer_pad])\n",
    "check_layers(67, 71, [layer_pad, layer_conv1])\n",
    "check_layers(67, 73, [layer_pad, layer_conv1, layer_relu])\n",
    "check_layers(67, 74, [layer_pad, layer_conv1, layer_relu, layer_conv('conv2_filter.npy', 'conv2_bias.npy', 'SAME')])\n",
    "check_layers(67, 76, [layer_pad, layer_conv1, layer_relu, layer_conv('conv2_filter.npy', 'conv2_bias.npy', 'SAME'), layer_relu])\n",
    "check_layers(76, 77, [layer_conv('conv3_filter.npy', 'conv3_bias.npy', 'VALID')])\n",
    "check_layers(76, 79, [layer_conv('conv3_filter.npy', 'conv3_bias.npy', 'VALID'), layer_relu])\n",
    "check_layers(76, 80, [layer_conv('conv3_filter.npy', 'conv3_bias.npy', 'VALID'), layer_relu, max_pool2x2])\n",
    "check_layers(80, 81, [layer_conv('conv4_filter.npy', 'conv4_bias.npy', 'SAME')])\n",
    "check_layers(80, 83, [layer_conv('conv4_filter.npy', 'conv4_bias.npy', 'SAME'), layer_relu])\n",
    "check_layers(83, 84, [layer_conv('conv5_filter.npy', 'conv5_bias.npy', 'VALID')])\n",
    "check_layers(83, 86, [layer_conv('conv5_filter.npy', 'conv5_bias.npy', 'VALID'), layer_relu])\n",
    "check_layers(86, 87, [layer_conv('conv6_filter.npy', 'conv6_bias.npy', 'SAME')])\n",
    "check_layers(86, 89, [layer_conv('conv6_filter.npy', 'conv6_bias.npy', 'SAME'), layer_relu])\n",
    "check_layers(89, 90, [layer_conv('conv7_filter.npy', 'conv7_bias.npy', 'VALID')])\n",
    "check_layers(89, 92, [layer_conv('conv7_filter.npy', 'conv7_bias.npy', 'VALID'), layer_relu])\n",
    "check_layers(89, 93, [layer_conv('conv7_filter.npy', 'conv7_bias.npy', 'VALID'), layer_relu, max_pool1x2])\n",
    "\n",
    "\n",
    "check_layers(67, 93, [layer_pad, layer_conv1, layer_relu, layer_conv('conv2_filter.npy', 'conv2_bias.npy', 'SAME'), layer_relu,\n",
    "    layer_conv('conv3_filter.npy', 'conv3_bias.npy', 'VALID'), layer_relu, max_pool2x2,\n",
    "    layer_conv('conv4_filter.npy', 'conv4_bias.npy', 'SAME'), layer_relu,\n",
    "    layer_conv('conv5_filter.npy', 'conv5_bias.npy', 'VALID'), layer_relu,\n",
    "    layer_conv('conv6_filter.npy', 'conv6_bias.npy', 'SAME'), layer_relu,\n",
    "    layer_conv('conv7_filter.npy', 'conv7_bias.npy', 'VALID'), layer_relu, max_pool1x2,\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383142dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "model2, model2_in, model2_out = get_model2(data.shape[0])\n",
    "\n",
    "print(dir(model2))\n",
    "print(model2.get_input_details())\n",
    "print(model2.get_output_details())\n",
    "pprint(model2.get_tensor_details())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
